(1) エクセルから指定の情報の取得とCSV出力の処理概略
この処理では、Excelファイルから広告枠IDを取得し、そのIDを使用してWebサイト（fam8）にログイン後、広告枠データを検索・取得し、取得したデータをCSVに保存する。

【全体の処理の流れ】
Excelから広告枠IDを取得

指定のExcelファイル (Enhance_広告枠検索対象.xlsx) から、日次レポート用の広告枠IDを取得する。
「日次レポート」「日次レポート (マイナビ)」の2つのシートから、それぞれの広告枠IDを抽出する。
WebDriverのセットアップとログイン

Selenium WebDriver を使用して、指定の管理サイト (fam8) にアクセスし、管理画面にログインする。
ChromeDriver を使用し、ブラウザを開いた状態でログインする。
広告枠IDを使用して検索

1回目の検索
Web画面の「広告枠検索ページ」に遷移し、検索条件を設定した後に、広告枠IDを入力し検索を実行する。
2回目以降の検索
すでに「広告枠検索ページ」にいるため、広告枠IDのみを変更して再検索を行う。
検索結果の取得

Webページから検索結果の表を取得し、Pandasを使ってデータを処理する。
必要なカラム（広告枠ID、広告枠名、Imp、Click、ネット）を抽出する。
取得したデータを DataFrame に格納する。
CSVにデータを保存

取得したデータを enhance_utf8(日次レポート).csv や enhance_utf8(日次レポート_マイナビ).csv に保存する。
すでに存在するCSVファイルがあれば追記する形でデータを追加する。
全ての処理が完了したらWebDriverを終了

すべての広告枠IDの検索が完了したら、Selenium WebDriver を終了する。
【分岐のポイント】
Excelの広告枠IDが空の場合

Excelから広告枠IDが取得できなかった場合は処理を終了する。
検索時の処理

初回の検索では、広告枠検索ページへ遷移し、条件を設定した上で検索を実行する。
2回目以降の検索では、検索ページは開いたままなので、広告枠IDを変更して再検索を行う。
検索結果が存在しない場合

指定した広告枠IDの検索結果が存在しない場合は、該当データが見つからなかったというログを出力する。
CSV保存時の処理

CSVがすでに存在する場合は、追記 (append) する形でデータを追加する。
CSVが存在しない場合は、新規作成 (write) してデータを保存する。
【使用する主なライブラリ】
selenium：ブラウザ操作を行い、Webサイトへのログインや検索を自動化する。
gspread：Google スプレッドシートのAPIと連携し、データの取得・保存を行う。
pandas：Webページの表データを解析・処理し、CSVに保存する。
openpyxl：Excelファイルを読み込み、広告枠IDを取得する。
os：CSVファイルの存在チェックなどを行う。

1. Excel から広告枠IDを取得
   「日次レポート」シートの広告枠ID
   「日次レポート (マイナビ)」シートの広告枠ID
　　 取得できなければ処理終了

2. Selenium をセットアップし、Webサイトにログイン
   ChromeDriver を起動
   fam8の管理画面へアクセス
   IDとパスワードを入力し、ログイン

3. 広告枠IDを使用して検索
   1回目の検索：広告枠ページに遷移し、検索実行
   2回目以降の検索：検索ページを開いたまま、IDを変更して検索

4. 検索結果を取得
   Webページから表データを取得
   Pandas で必要なデータを抽出

5. 取得したデータを CSV に保存
   CSVがある場合：追記
   CSVがない場合：新規作成

6. すべての検索が終了後、WebDriver を終了

【この後の詳細設計について】
次に、各処理を詳細に分けて説明する。以下の内容について順番に解説を進めていく。

Excelからの広告枠ID取得の処理
Selenium WebDriver のセットアップとログイン
広告枠IDを使った検索処理
検索結果の取得とデータ処理
CSV保存の処理
検索終了後の後処理（WebDriverの終了など）


(2) 情報のアップロードの処理概略
この処理では、(1) の処理で取得・保存した CSV ファイルを Google スプレッドシートにアップロードする。
データを適切なフォーマットで挿入し、指定のカラムにマッピングを行いながら、
スプレッドシートの既存の関数（E列, G列）を保持したまま追加する。

【全体の処理の流れ】
CSV ファイルの存在確認

CSVファイル (enhance_utf8(日次レポート).csv / enhance_utf8(日次レポート_マイナビ).csv) が存在するか確認する。
存在しない場合はスキップし、エラーメッセージを出力。
CSV ファイルの読み込み

pandas を使用して CSV データを読み込む。
必要なカラムを選択し、データを加工する。
Google スプレッドシートへ接続

gspread を使用し、Google スプレッドシートへ API 接続を確立する。
指定のシート (日次レポート / 日次レポート (マイナビ)) にアクセスする。
スプレッドシートの最終行の取得

worksheet.get_all_values() でデータを取得し、最終行を算出する。
追加するデータの挿入位置（最終行の 1 行下）を決定。
データのアップロード

worksheet.append_rows() を用いて、CSVデータをスプレッドシートに追加。
スプレッドシートの既存関数を削除せずにデータを追加する。
A列のフォーマットを調整

A列（日付列）のフォーマットを「右寄せ + 日付フォーマット」に設定。
アップロードが完了したら CSV を削除

os.remove() を用いて、処理が完了した CSV ファイルを削除する。
【分岐のポイント】
CSV ファイルが存在しない場合

該当する CSV ファイルがない場合はスキップし、エラーを出力。
データのカラム順調整

CSVデータにはスプレッドシートと異なるカラム順が含まれているため、
必要なカラムを適切な順序に並べ替えてアップロードする。
E列 (CTR)、G列 (CPM) の計算式を削除しないよう、ダミーの E列 を追加。
スプレッドシートの最終行を取得

追加位置を決定するため、現在のスプレッドシートのデータの最終行を取得。
既存のデータを上書きせず、最終行の1つ下からデータを追加する。
既存の関数 (E列, G列) を削除しない

スプレッドシート内に既に存在する関数 (CTR, CPM) を保持したまま、
データのみを追加するように処理を設計。
CSVデータのアップロード

worksheet.append_rows() を使用して、Google スプレッドシートに CSV の内容をアップロード。
アップロード後に A列（"日付"）のフォーマットを調整する。
処理完了後に CSV ファイルを削除

スプレッドシートへのデータ追加が完了したら、元の CSV ファイルを削除する。
【使用する主なライブラリ】
pandas：CSV ファイルの読み込みとデータの加工を行う。
gspread：Google スプレッドシートの API を用いてデータをアップロードする。
os：処理完了後に CSV ファイルを削除する。

【処理の概要図】

1. CSV ファイルの確認
   ファイルが存在しない → スキップ
   ファイルが存在する → 読み込みへ進む

2. CSV ファイルの読み込み
   必要なカラムのみ抽出
   カラム順をスプレッドシートに合わせて整理

3. Google スプレッドシートへ接続
   認証処理（gspread を使用）
   指定のシートを開く

4. スプレッドシートの最終行の取得
   `get_all_values()` で現在のデータを取得
    最終行の1つ下の行からデータを挿入

5. CSV データのアップロード
   `append_rows()` を使用してデータを追加
   　既存の関数 (E列, G列) を保持

6. A列のフォーマットを調整
   `A列` を右寄せ + 日付フォーマットに変更

7. 処理完了後に CSV を削除
   `os.remove()` を使用し、元の CSV を削除

